<section class="page-section" id="page-108">
    <div class="page-header">
        <div class="page-number">108</div>
        <div class="page-title">
            <h3>Optimizare Convexa si Constransa</h3>
            <span>Capitolul 4 - Sectiunea 4.4</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT)-page-108.jpg"
             alt="Pagina 108" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Optimizare Convexa</h4>
                <p>Cel mai de succes domeniu din optimizare specializata este <strong>optimizarea convexa</strong>. Algoritmii de optimizare convexa ofera multe garantii prin restrictii mai puternice. Sunt aplicabili doar functiilor convexe - functii pentru care Hessianul este pozitiv semidefinit peste tot. Astfel de functii sunt "bine comportate": nu au puncte saddle si toate minimele locale sunt neaparat minime globale. Totusi, majoritatea problemelor din deep learning sunt non-convexe.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Functii Convexe</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import numpy as np

def is_convex_check(hessian_func, domain_points):
    """Verifica daca o functie pare convexa (H poz. semidef.)"""
    for x in domain_points:
        H = hessian_func(x)
        eigenvalues = np.linalg.eigvals(H)
        if np.any(eigenvalues < -1e-10):  # Toleranta numerica
            return False
    return True

# Exemple
examples = [
    ("f(x) = x¬≤", lambda x: np.array([[2]])),  # Convexa
    ("f(x) = |x|", lambda x: np.array([[0]])), # Convexa (poz. semidef.)
    ("f(x,y) = x¬≤+y¬≤", lambda x: np.array([[2,0],[0,2]])),  # Convexa
    ("f(x,y) = x¬≤-y¬≤", lambda x: np.array([[2,0],[0,-2]])), # NON-convexa
]

print("Verificare convexitate:")
print("-" * 45)
for name, hess in examples:
    # Test pe cateva puncte
    test_points = [np.zeros(1 if "y" not in name else 2)]
    is_convex = is_convex_check(hess, test_points)
    symbol = "‚úì CONVEXA" if is_convex else "‚úó NON-CONVEXA"
    print(f"{name:20s}: {symbol}")
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Convex in Deep Learning</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <h5>Unde apare convexitatea?</h5>
                                <ul style="margin-left: 20px;">
                                    <li><strong>Loss functions:</strong> MSE, cross-entropy sunt convexe in predictii (dar nu in weights!)</li>
                                    <li><strong>Regularizare:</strong> L1, L2 norm sunt convexe</li>
                                    <li><strong>SVM:</strong> Problema duala este convexa</li>
                                    <li><strong>Logistic Regression:</strong> Este convexa (un singur layer, fara hidden)</li>
                                </ul>
                                <p style="margin-top: 10px; color: var(--warning);">Dar retelele neuronale cu hidden layers sunt NON-CONVEXE in parametri!</p>
                            </div>
                            <div class="reference-list" style="margin-top: 15px;">
                                <div class="reference-item">
                                    <strong>Boyd & Vandenberghe:</strong> "Convex Optimization" - cartea de referinta
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>4.4 Optimizare Constransa</h4>
                <p>Uneori vrem nu doar sa minimizam/maximizam f(x) peste toate valorile posibile ale lui x, ci sa gasim max/min pentru x intr-o multime S. Aceasta se numeste <strong>optimizare constransa</strong>. Punctele x care apartin multimii S se numesc puncte <strong>fezabile</strong>. Adesea vrem sa gasim o solutie care este "mica" intr-un sens, impunand o constrangere de norma precum ||x|| ‚â§ 1.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Optimizare Constransa</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import numpy as np

def projected_gradient_descent(f, grad_f, project, x0, lr, n_iter):
    """GD cu proiectie pe multimea fezabila"""
    x = x0.copy()
    history = [x.copy()]

    for _ in range(n_iter):
        # Pas de gradient
        x = x - lr * grad_f(x)
        # Proiectie pe constrangere
        x = project(x)
        history.append(x.copy())

    return x, history

# Minimizam f(x) = (x-2)¬≤ + (y-2)¬≤ cu constrangere ||x|| <= 1
def f(x): return (x[0]-2)**2 + (x[1]-2)**2
def grad_f(x): return np.array([2*(x[0]-2), 2*(x[1]-2)])
def project_to_ball(x):
    """Proiecteaza pe bila unitara"""
    norm = np.linalg.norm(x)
    if norm > 1:
        return x / norm
    return x

x0 = np.array([0.0, 0.0])
x_opt, hist = projected_gradient_descent(f, grad_f, project_to_ball,
                                         x0, lr=0.1, n_iter=50)

print("Minimizam (x-2)¬≤ + (y-2)¬≤ cu ||x|| <= 1")
print(f"\nFara constrangere: optim la (2, 2)")
print(f"Cu constrangere: optim la {x_opt}")
print(f"Norma solutiei: {np.linalg.norm(x_opt):.4f}")
print(f"Valoare functie: {f(x_opt):.4f}")

# Solutia analitica
x_analytical = np.array([1, 1]) / np.sqrt(2)
print(f"\nSolutie analitica: {x_analytical}")
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Vizualizare: Regiune Fezabila</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="background: var(--bg-dark); padding: 20px; border-radius: 8px;">
                                <svg viewBox="0 0 200 200" style="width: 100%; max-width: 200px; display: block; margin: 0 auto;">
                                    <!-- Contururi functie obiectiv -->
                                    <circle cx="150" cy="50" r="30" fill="none" stroke="var(--bg-lighter)" stroke-width="1"/>
                                    <circle cx="150" cy="50" r="60" fill="none" stroke="var(--bg-lighter)" stroke-width="1"/>
                                    <circle cx="150" cy="50" r="90" fill="none" stroke="var(--bg-lighter)" stroke-width="1"/>
                                    <!-- Regiune fezabila -->
                                    <circle cx="100" cy="100" r="50" fill="rgba(0, 200, 100, 0.2)" stroke="var(--success)" stroke-width="2"/>
                                    <!-- Optim neconstrans -->
                                    <circle cx="150" cy="50" r="5" fill="#ff6464"/>
                                    <text x="155" y="45" fill="#ff6464" font-size="10">optim liber</text>
                                    <!-- Optim constrans -->
                                    <circle cx="135" cy="65" r="5" fill="var(--success)"/>
                                    <text x="140" y="75" fill="var(--success)" font-size="10">optim constrans</text>
                                    <!-- Legenda -->
                                    <text x="100" y="170" fill="var(--text-secondary)" font-size="10" text-anchor="middle">Regiune fezabila S</text>
                                </svg>
                                <p style="text-align: center; margin-top: 15px;">Optimul constrans este pe frontiera lui S!</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Abordari pentru Constrangeri</h4>
                <p>O abordare simpla: modificam gradient descent pentru a tine cont de constrangeri. Cu un pas constant mic Œµ, facem pasul de gradient si apoi <strong>proiectam</strong> rezultatul inapoi in S. Cu line search, cautam doar peste valori Œµ care produc puncte fezabile. O abordare mai sofisticata: proiectam gradientul in spatiul tangent al regiunii fezabile inainte de a face pasul.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Tipuri de Constrangeri</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px;">
                                <div style="background: var(--bg-lighter); padding: 15px; border-radius: 8px;">
                                    <strong>Constrangeri de Egalitate</strong>
                                    <p style="font-family: monospace; margin-top: 10px;">g(x) = 0</p>
                                    <p style="font-size: 0.9rem; margin-top: 5px;">Ex: x‚ÇÅ + x‚ÇÇ = 1</p>
                                </div>
                                <div style="background: var(--bg-lighter); padding: 15px; border-radius: 8px;">
                                    <strong>Constrangeri de Inegalitate</strong>
                                    <p style="font-family: monospace; margin-top: 10px;">h(x) ‚â§ 0</p>
                                    <p style="font-size: 0.9rem; margin-top: 5px;">Ex: ||x|| ‚â§ 1</p>
                                </div>
                            </div>
                            <div class="key-concept" style="margin-top: 15px;">
                                <h5>In Deep Learning</h5>
                                <ul style="margin-left: 20px;">
                                    <li><strong>Weight clipping:</strong> ||W|| ‚â§ c (pentru WGAN)</li>
                                    <li><strong>Gradient clipping:</strong> ||‚àá|| ‚â§ threshold</li>
                                    <li><strong>Simplex:</strong> Œ£w·µ¢ = 1, w·µ¢ ‚â• 0 (pentru attention)</li>
                                    <li><strong>Orthogonal:</strong> W·µÄW = I</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
