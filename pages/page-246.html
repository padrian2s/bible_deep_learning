<section class="page-section" id="page-246">
    <div class="page-header">
        <div class="page-number">246</div>
        <div class="page-title">
            <h3>7.1.1 Regularizare L¬≤ (Weight Decay)</h3>
            <span>L¬≤ Parameter Regularization</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/page-246.jpg"
             alt="Pagina 246" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Regularizarea L¬≤ - Weight Decay</h4>
                <p>Cea mai comuna penalizare pe norma parametrilor este regularizarea L¬≤, cunoscuta si ca <strong>weight decay</strong>, <strong>ridge regression</strong> sau <strong>regularizare Tikhonov</strong>. Aceasta strategie "impinge" weights-urile mai aproape de origine adaugand termenul Œ©(Œ∏) = ¬Ω||w||¬≤ la functia obiectiv:</p>
                <div class="formula" style="margin: 15px 0; padding: 15px; background: var(--bg-dark); border-radius: 8px; text-align: center; font-size: 1.1rem;">
                    JÃÉ(w; X, y) = (Œ±/2)w‚ä§w + J(w; X, y)
                </div>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Cod: Weight Decay in PyTorch</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import torch.optim as optim

# Metoda 1: Direct in optimizer
optimizer = optim.SGD(
    model.parameters(),
    lr=0.01,
    weight_decay=0.001  # Œ± = 0.001
)

# Metoda 2: Manual (pentru mai mult control)
optimizer = optim.SGD(model.parameters(), lr=0.01)

for epoch in range(epochs):
    loss = criterion(model(X), y)

    # Adaugam L2 penalty manual
    l2_reg = sum(p.pow(2).sum() for p in model.parameters())
    loss = loss + 0.001 * l2_reg

    loss.backward()
    optimizer.step()
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Gradientul si Regula de Update</h4>
                <p>Gradientul functiei obiectiv regularizate este:</p>
                <div class="formula" style="margin: 15px 0; padding: 15px; background: var(--bg-dark); border-radius: 8px; text-align: center;">
                    ‚àá<sub>w</sub>JÃÉ(w; X, y) = Œ±w + ‚àá<sub>w</sub>J(w; X, y)
                </div>
                <p>La fiecare pas de gradient, update-ul devine:</p>
                <div class="formula" style="margin: 15px 0; padding: 15px; background: var(--bg-dark); border-radius: 8px; text-align: center;">
                    w ‚Üê w - Œµ(Œ±w + ‚àá<sub>w</sub>J(w; X, y))
                </div>
                <p>Sau echivalent:</p>
                <div class="formula" style="margin: 15px 0; padding: 15px; background: var(--bg-dark); border-radius: 8px; text-align: center;">
                    w ‚Üê (1 - ŒµŒ±)w - Œµ‚àá<sub>w</sub>J(w; X, y)
                </div>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>De ce "Weight Decay"?</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <p>Observa factorul <strong>(1 - ŒµŒ±)</strong> care inmulteste w inainte de gradient step. Acest factor este < 1, deci la fiecare pas weights-urile sunt "micrate" (decay). De aici numele "weight decay".</p>
                            </div>
                            <div style="margin-top: 15px; padding: 15px; background: var(--bg-lighter); border-radius: 8px;">
                                <strong>Exemplu numeric:</strong>
                                <ul style="margin-top: 10px; font-family: monospace;">
                                    <li>Œµ = 0.01 (learning rate)</li>
                                    <li>Œ± = 0.1 (weight decay)</li>
                                    <li>Factor: 1 - 0.01√ó0.1 = 0.999</li>
                                    <li>La fiecare pas, w ‚Üí 0.999 √ó w</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Alte nume pentru L¬≤</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <ul class="reference-list">
                                <li class="reference-item">
                                    <span>üìä</span>
                                    <div><strong>Ridge Regression</strong> - In statistica, pentru regresie liniara</div>
                                </li>
                                <li class="reference-item">
                                    <span>üî¨</span>
                                    <div><strong>Tikhonov Regularization</strong> - In matematica aplicata si probleme inverse</div>
                                </li>
                                <li class="reference-item">
                                    <span>üß†</span>
                                    <div><strong>Weight Decay</strong> - In deep learning, datorita efectului de "diminuare"</div>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
