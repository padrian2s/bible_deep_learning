<section class="page-section" id="page-161">
    <div class="page-header">
        <div class="page-number">161</div>
        <div class="page-title">
            <h3>Decision Trees si Unsupervised Learning</h3>
            <span>Capitolul 5 - Sectiunile 5.7.3 si 5.8</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-161.jpg"
             alt="Pagina 161" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Decision Trees (Breiman et al., 1984)</h4>
                <p>Un alt tip de algoritm care imparte spatiul in regiuni cu parametri separati per regiune este <strong>decision tree</strong>. Fiecare nod al arborelui este asociat cu o regiune, iar nodurile interne imparte acea regiune in sub-regiuni (tipic folosind <strong>axis-aligned cuts</strong>). Decision trees sunt antrenate cu algoritmi specializati (in afara scopului acestei carti). Algoritmul poate fi considerat <strong>non-parametric</strong> daca poate invata un arbore de dimensiune arbitrara, desi tipic sunt regularizate cu constrangeri de dimensiune.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Referinte Decision Trees</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="reference-list">
                                <div class="reference-item">
                                    <strong>Breiman et al. (1984)</strong> - Classification and Regression Trees (CART)
                                </div>
                                <div class="reference-item">
                                    <strong>Murphy (2012)</strong> - Machine Learning: A Probabilistic Perspective
                                </div>
                                <div class="reference-item">
                                    <strong>Bishop (2006)</strong> - Pattern Recognition and Machine Learning
                                </div>
                                <div class="reference-item">
                                    <strong>Hastie et al. (2001)</strong> - Elements of Statistical Learning
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Limitarile Decision Trees</h4>
                <p>Decision trees, folosind <strong>axis-aligned splits</strong> si outputs constante in fiecare nod, au dificultati la rezolvarea unor probleme simple pentru logistic regression. De exemplu, daca clasa pozitiva apare oriunde x‚ÇÇ > x‚ÇÅ, decision boundary nu este axis-aligned. Arborele va trebui sa aproximeze boundary-ul de decizie cu multe noduri, implementand o <strong>step function</strong> care merge constant inainte si inapoi peste adevaratul boundary.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Vizualizare: Axis-Aligned Limitation</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <h5>Problema Diagonala</h5>
                                <div style="background: var(--bg-dark); padding: 20px; border-radius: 8px; text-align: center;">
                                    <p>True boundary: <strong>x‚ÇÇ = x‚ÇÅ</strong> (linie diagonala)</p>
                                    <div style="margin: 15px 0; font-family: monospace;">
                                        <pre style="color: var(--text-secondary);">
  x‚ÇÇ ‚îÇ    ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì (clasa 1)
     ‚îÇ   ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
     ‚îÇ  ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
     ‚îÇ ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
     ‚îÇ‚ñì‚ñì‚ñì‚ñì‚ñì‚ñì
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ x‚ÇÅ
        (clasa 0)
                                        </pre>
                                    </div>
                                    <p style="font-size: 0.9rem;">Decision tree: step function zig-zag</p>
                                    <p style="font-size: 0.9rem; color: var(--warning);">Logistic regression: o singura linie!</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>5.8 Unsupervised Learning Algorithms</h4>
                <p>Reamintim din sectiunea 5.1.3 ca algoritmii <strong>unsupervised</strong> sunt cei care experimenteaza doar "features" fara semnal de supervizare. Distinctia intre supervised si unsupervised nu este formal si rigid definita - nu exista un test obiectiv pentru a distinge daca o valoare este feature sau target. Informal, unsupervised learning se refera la incercarile de a extrage informatii dintr-o distributie care nu necesita human labor pentru adnotare. Termenul este asociat cu <strong>density estimation</strong>, invatarea de a genera esantioane, <strong>denoising</strong>, gasirea unui <strong>manifold</strong>, sau <strong>clustering</strong>.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Unsupervised Tasks</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import numpy as np

np.random.seed(42)

# Date neetichetate (fara y!)
X = np.vstack([
    np.random.randn(50, 2) + [0, 0],
    np.random.randn(50, 2) + [5, 5],
    np.random.randn(50, 2) + [10, 0]
])

# Task 1: Clustering
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X)
print("Clustering:")
print(f"  Gasit {len(np.unique(clusters))} clustere")

# Task 2: Dimensionality Reduction
pca = PCA(n_components=1)
X_reduced = pca.fit_transform(X)
print(f"\nPCA:")
print(f"  {X.shape[1]}D -> {X_reduced.shape[1]}D")
print(f"  Variance explained: {pca.explained_variance_ratio_[0]:.1%}")

print("\n=> Fara labels, invatam structura datelor!")
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
