<section class="page-section" id="page-334">
    <div class="page-header">
        <div class="page-number">334</div>
        <div class="page-title">
            <h3>Batch Normalization: Formule</h3>
            <span>Normalizarea Activarilor</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT)-page-334.jpg"
             alt="Pagina 334" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Formula Batch Normalization</h4>
                <p>Batch normalization normalizeaza activarile H la medie 0 si varianta 1, apoi aplica parametri invatati Œ≥ si Œ≤ pentru a reda expresivitatea. Formula: H' = (H - Œº) / œÉ, apoi output = Œ≥H' + Œ≤.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Formule Complete</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="formula">
                                Œº = (1/m) Œ£·µ¢ H<sub>i,:</sub><br><br>
                                œÉ = ‚àö(Œ¥ + (1/m) Œ£·µ¢ (H<sub>i,:</sub> - Œº)¬≤)<br><br>
                                H' = (H - Œº) / œÉ
                            </div>
                            <p style="color: var(--text-secondary); margin-top: 15px;">Œº si œÉ sunt calculate <strong>per minibatch</strong> la training. Œ¥ (~10‚Åª‚Å∏) evita impartirea la zero. Gradientul se propaga prin aceste operatii!</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>De Ce Functioneaza</h4>
                <p>Inainte de batch norm, gradientul putea propune cresterea mediei unui layer, iar normalizarea ar fi anulat aceasta schimbare - wasted computation! Batch norm reparametrizeaza modelul astfel incat media e controlata direct de Œ≤.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Beneficii Batch Norm</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <ul style="color: var(--text-secondary); line-height: 2;">
                                <li><strong>Learning rate mai mare:</strong> Reteaua e mai stabila, putem face pasi mai mari</li>
                                <li><strong>Initializare mai putin critica:</strong> Normalizarea corecteaza distributia</li>
                                <li><strong>Regularizare implicita:</strong> Zgomotul din calculul Œº, œÉ pe minibatch</li>
                                <li><strong>Retele mai deep:</strong> Permite antrenarea retelelor cu sute de layere</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>La Test Time</h4>
                <p>La inferenta nu avem minibatch, deci nu putem calcula Œº, œÉ. Solutia: folosim <strong>running averages</strong> colectate in timpul antrenarii. Œº si œÉ devin constante fixe la test time.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Cod PyTorch</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
# Batch Norm in PyTorch
import torch.nn as nn

# Pentru layers fully connected
bn = nn.BatchNorm1d(num_features=256)

# Pentru CNN (normalizeaza per canal)
bn_conv = nn.BatchNorm2d(num_features=64)

# La training: calculeaza Œº, œÉ din batch
# La eval: foloseste running_mean, running_var
model.eval()  # Switch to inference mode
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
