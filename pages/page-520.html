<section class="page-section" id="page-520">
    <div class="page-header">
        <div class="page-number">520</div>
        <div class="page-title">
            <h3>Autoencodere Sparse</h3>
            <span>Capitolul 14 - Sectiunea 14.2.1</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-520.jpg"
             alt="Pagina 520" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>14.2.1 Sparse Autoencoders</h4>
                <p>Un <strong>sparse autoencoder</strong> adauga o penalizare de sparsitate <strong>Œ©(h)</strong> pe codul h, pe langa eroarea de reconstructie. Functia de cost devine: <strong>L(x, g(f(x))) + Œ©(h)</strong>. Aceasta forteaza majoritatea unitatilor din h sa fie inactive (aproape de zero) pentru orice input dat. Sparsitatea este utila pentru clasificare si alte task-uri deoarece forteaza modelul sa invete caracteristici distinctive.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Sparse Autoencoder</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import torch
import torch.nn as nn

class SparseAutoencoder(nn.Module):
    def __init__(self, input_dim, code_dim, sparsity_weight=0.1):
        super().__init__()
        self.sparsity_weight = sparsity_weight
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, code_dim),
            nn.Sigmoid()  # Activari intre 0 si 1
        )
        self.decoder = nn.Sequential(
            nn.Linear(code_dim, 256),
            nn.ReLU(),
            nn.Linear(256, input_dim)
        )

    def forward(self, x):
        h = self.encoder(x)
        r = self.decoder(h)
        return r, h

    def sparsity_loss(self, h):
        # L1 penalty: suma valorilor absolute
        return self.sparsity_weight * torch.mean(torch.abs(h))

# Antrenare
def train_step(model, x, optimizer):
    r, h = model(x)
    recon_loss = nn.MSELoss()(r, x)
    sparse_loss = model.sparsity_loss(h)
    total_loss = recon_loss + sparse_loss  # L(x,g(f(x))) + Œ©(h)

    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
    return total_loss.item()
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Vizualizare: Cod Sparse</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">
                                <div style="background: var(--bg-dark); padding: 15px; border-radius: 8px;">
                                    <h5>Cod Dens (normal)</h5>
                                    <div style="display: flex; gap: 3px; flex-wrap: wrap; margin-top: 10px;">
                                        <span style="background: var(--primary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--primary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--secondary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--primary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--secondary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--primary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--secondary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--primary); width: 20px; height: 20px; border-radius: 3px;"></span>
                                    </div>
                                    <p style="font-size: 0.8rem; margin-top: 10px; color: var(--text-secondary);">Majoritatea unitatilor active</p>
                                </div>
                                <div style="background: var(--bg-dark); padding: 15px; border-radius: 8px;">
                                    <h5>Cod Sparse</h5>
                                    <div style="display: flex; gap: 3px; flex-wrap: wrap; margin-top: 10px;">
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--accent); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: var(--accent); width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                        <span style="background: #333; width: 20px; height: 20px; border-radius: 3px;"></span>
                                    </div>
                                    <p style="font-size: 0.8rem; margin-top: 10px; color: var(--text-secondary);">Putine unitati active (sparse)</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Interpretarea Bayesiana</h4>
                <p>Putem interpreta penalizarea Œ©(h) ca un <strong>regularizator</strong> adaugat la o retea feedforward pentru task-ul de copiere (nesupervizat), posibil combinat cu un task supervizat. Spre deosebire de weight decay care are interpretare Bayesiana clara (prior pe parametri), regularizarea de sparsitate nu are o interpretare simpla deoarece depinde de <strong>date</strong>, nu doar de model. Totusi, putem gandi la aceste penalizari ca exprimand implicit preferinte asupra functiilor.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>MAP vs Regularizare</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="formula" style="background: var(--bg-dark); padding: 20px; border-radius: 8px; text-align: center;">
                                <p>Regularized Maximum Likelihood:</p>
                                <p style="font-size: 1.2rem; margin: 10px 0;">max log p(Œ∏|x) = max [log p(x|Œ∏) + log p(Œ∏)]</p>
                                <p style="color: var(--text-secondary);">log p(x|Œ∏) = likelihood, log p(Œ∏) = prior (regularizare)</p>
                            </div>
                            <div class="key-concept" style="margin-top: 15px;">
                                <p><strong>Diferenta critica:</strong> Weight decay penalizeaza parametrii Œ∏ (independent de date), dar sparsity penalizeaza activarile h = f(x; Œ∏) care depind de input!</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Framework: Sparse Coding Aproximat</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="background: var(--bg-dark); padding: 20px; border-radius: 8px;">
                                <p style="margin-bottom: 15px;">Sparse autoencoder poate fi vazut ca <strong>aproximare</strong> a sparse coding clasic:</p>
                                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 15px;">
                                    <div style="background: var(--primary); padding: 15px; border-radius: 8px;">
                                        <strong>Sparse Coding Clasic</strong>
                                        <p style="font-size: 0.9rem; margin-top: 5px;">min ||x - Dh||¬≤ + Œª||h||‚ÇÅ</p>
                                        <p style="font-size: 0.8rem; color: var(--text-secondary);">Optimizare iterativa pentru fiecare x</p>
                                    </div>
                                    <div style="background: var(--secondary); padding: 15px; border-radius: 8px;">
                                        <strong>Sparse Autoencoder</strong>
                                        <p style="font-size: 0.9rem; margin-top: 5px;">h = f(x; Œ∏) direct</p>
                                        <p style="font-size: 0.8rem; color: var(--text-secondary);">Encoder invata sa aproximeze solutia</p>
                                    </div>
                                </div>
                                <p style="margin-top: 15px; text-align: center; color: var(--accent);">Encoder-ul "amortizeaza" costul optimizarii!</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Utilizari Practice ale Sparse AE</h4>
                <p>Sparse autoencoderele sunt folosite pentru a invata <strong>features pentru clasificare</strong>. Un autoencoder antrenat cu sparsitate trebuie sa raspunda la caracteristici statistice unice ale datasetului, nu doar sa actioneze ca o functie identitate. Features-urile sparse sunt mai <strong>interpretabile</strong> si mai usor de folosit pentru downstream tasks precum clasificarea sau detectia anomaliilor.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Aplicatie: Feature Learning pentru Clasificare</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import torch
import torch.nn as nn

class SparseFeatureExtractor(nn.Module):
    """
    Pipeline: Sparse AE pentru features + Classifier
    1. Antrenam AE unsupervised cu sparsity
    2. Folosim encoder ca feature extractor
    3. Antrenam classifier pe features
    """
    def __init__(self, input_dim, feature_dim, num_classes):
        super().__init__()
        # Pre-trained sparse encoder
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, feature_dim),
            nn.ReLU()  # Sparse activations
        )
        # Classifier head
        self.classifier = nn.Linear(feature_dim, num_classes)

    def extract_features(self, x):
        return self.encoder(x)

    def classify(self, x):
        features = self.encoder(x)
        return self.classifier(features)

# Avantaj: features sparse sunt mai interpretabile
# Fiecare unitate corespunde unui "concept" distinct
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Context Modern: Mechanistic Interpretability</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <h5>Sparse Autoencoders in 2024</h5>
                                <p>Cercetatorii de la Anthropic si OpenAI folosesc sparse autoencoders pentru <strong>mechanistic interpretability</strong> - intelegerea reprezentarilor interne ale LLM-urilor!</p>
                                <ul style="margin: 10px 0 0 20px; font-size: 0.9rem;">
                                    <li>Antrenam SAE pe activarile unui layer din GPT/Claude</li>
                                    <li>Fiecare feature sparse corespunde unui "concept"</li>
                                    <li>Putem identifica ce "stie" modelul</li>
                                    <li>Aplicatii: safety, alignment, debugging</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
