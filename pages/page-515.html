<section class="page-section" id="page-515">
    <div class="page-header">
        <div class="page-number">515</div>
        <div class="page-title">
            <h3>Figura 13.3: Manifold Gaussian</h3>
            <span>Interpretarea Geometrica</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-515.jpg"
             alt="Pagina 515" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Figura 13.3: "Pancake" Gaussian</h4>
                <p>Figura ilustreaza cum PCA captureaza concentrarea probabilitatii langa un <strong>manifold de dimensiune joasa</strong>. Distributia Gaussiana arata ca o "clatita" (pancake) - lata in directiile principale, subtire ortogonal pe ele.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Interpretare</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="display: grid; gap: 15px;">
                                <div style="background: var(--bg-lighter); padding: 15px; border-radius: 8px;">
                                    <strong style="color: var(--primary);">Directii in Plan (mari variances)</strong>
                                    <p style="color: var(--text-secondary); margin-top: 5px;">= "semnal" = coordonate pe manifold</p>
                                </div>
                                <div style="background: var(--bg-lighter); padding: 15px; border-radius: 8px;">
                                    <strong style="color: var(--accent);">Directie Ortogonala (varianta mica)</strong>
                                    <p style="color: var(--text-secondary); margin-top: 5px;">= "zgomot" = eroare de reconstructie</p>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Eroarea de Reconstructie</h4>
                <p>Encoder-ul si decoder-ul care minimizeaza eroarea de reconstructie ||x - xÌ‚||Â² corespund la: V = W, mu = b = E[x], si coloanele lui W formeaza o baza ortonormala pentru principalii eigenvectori ai covariantei.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Formula</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="formula">
                                C = E[(x - mu)(x - mu)<sup>T</sup>] (covarianta)<br><br>
                                min E[||x - xÌ‚||Â²] = sum<sub>i=d+1</sub><sup>D</sup> lambda<sub>i</sub>
                            </div>
                            <p style="color: var(--text-secondary); margin-top: 15px;">Eroarea de reconstructie = suma eigenvalues pentru directiile ignorate. Daca covarianta are rank d, eroarea e 0!</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Maximizare Varianta vs Minimizare Eroare</h4>
                <p>Se poate arata ca solutia de mai sus e echivalenta cu <strong>maximizarea variantei</strong> elementelor lui h, sub constrangerea W ortogonal. Ambele duc la aceeasi solutie PCA!</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>Legatura cu Linear Autoencoders</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <p style="color: var(--text-secondary);">Aceasta interpretare se aplica nu doar PCA-ului traditional, ci si oricarui <strong>autoencoder liniar</strong> care invata matrici W si V pentru a minimiza eroarea de reconstructie.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
