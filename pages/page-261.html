<section class="page-section" id="page-261">
    <div class="page-header">
        <div class="page-number">261</div>
        <div class="page-title">
            <h3>7.8 Early Stopping</h3>
            <span>Oprirea Timpurie a Antrenamentului</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/page-261.jpg"
             alt="Pagina 261" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Figura 7.3: Learning Curves</h4>
                <p>Figura arata cum evolueaza loss-ul in timp (epochs). Observam ca training loss scade constant, dar <strong>validation loss</strong> incepe sa creasca dupa un punct - forma clasica "U-shaped". Aceasta comportare apare foarte consistent in deep learning.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Interpretare Learning Curves</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="background: var(--bg-lighter); padding: 20px; border-radius: 8px;">
                                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                                    <span style="color: var(--primary);">Training Loss â†“</span>
                                    <span>â†’ Epochs â†’</span>
                                    <span style="color: var(--success);">Validation Loss âˆª</span>
                                </div>
                                <div style="height: 60px; background: linear-gradient(to right, var(--bg-dark), var(--bg-dark)); border-radius: 8px; position: relative;">
                                    <div style="position: absolute; bottom: 10px; left: 10px; right: 10px; height: 2px; background: var(--primary);"></div>
                                    <div style="position: absolute; top: 40px; left: 10px; width: 40%; height: 2px; background: var(--success);"></div>
                                    <div style="position: absolute; top: 20px; left: 50%; right: 10px; height: 2px; background: var(--success);"></div>
                                </div>
                                <p style="margin-top: 15px; text-align: center; color: var(--text-secondary);">Punctul de minim al validation loss = momentul optim pentru oprire</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Early Stopping - Ideea de Baza</h4>
                <p>Cand antrenam modele mari cu capacitate suficienta pentru overfitting, training error scade constant, dar validation error incepe sa creasca. Putem obtine un model cu eroare mai buna pe validation (si sperabil pe test) <strong>revenind la parametrii din momentul cu cel mai mic validation error</strong>.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Implementare Simpla</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
best_val_loss = float('inf')
best_params = None
patience_counter = 0
patience = 10  # cat asteptam fara imbunatatire

for epoch in range(max_epochs):
    train_one_epoch(model)
    val_loss = evaluate(model, val_loader)

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_params = copy.deepcopy(model.state_dict())
        patience_counter = 0  # reset
    else:
        patience_counter += 1

    if patience_counter >= patience:
        print(f"Early stopping at epoch {epoch}")
        break

# Restore best parameters
model.load_state_dict(best_params)
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>De ce functioneaza</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <p>De fiecare data cand eroarea pe validation set se imbunatateste, salvam o copie a parametrilor. Cand algoritmul termina, returnam acesti parametri salvati, nu ultimii parametri.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
