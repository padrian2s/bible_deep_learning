<section class="page-section" id="page-518">
    <div class="page-header">
        <div class="page-number">518</div>
        <div class="page-title">
            <h3>Autoencodere Undercomplete</h3>
            <span>Capitolul 14 - Sectiunea 14.1</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-518.jpg"
             alt="Pagina 518" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Figura 14.1: Structura Generala</h4>
                <p>Diagrama arata structura unui autoencoder: inputul <strong>x</strong> este mapat la reprezentarea interna <strong>h</strong> (codul) prin encoder f, apoi h este mapat la reconstructia <strong>r</strong> prin decoder g. Encoderul comprima informatia, decoderul o decomprimala. Codul h este "bottleneck-ul" care forteaza reteaua sa invete ce este esential in date.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Vizualizare: Fluxul Datelor</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="text-align: center; padding: 20px;">
                                <div style="display: inline-block; background: var(--bg-dark); padding: 30px; border-radius: 12px;">
                                    <div style="font-size: 1.2rem; margin-bottom: 20px;">
                                        <span style="background: var(--primary); padding: 10px 20px; border-radius: 8px;">x (input)</span>
                                    </div>
                                    <div style="font-size: 1.5rem; margin: 10px 0;">â†“ <span style="font-size: 0.9rem;">f (encoder)</span></div>
                                    <div style="font-size: 1.2rem; margin: 20px 0;">
                                        <span style="background: var(--accent); padding: 8px 15px; border-radius: 50%;">h</span>
                                    </div>
                                    <div style="font-size: 1.5rem; margin: 10px 0;">â†“ <span style="font-size: 0.9rem;">g (decoder)</span></div>
                                    <div style="font-size: 1.2rem; margin-top: 20px;">
                                        <span style="background: var(--success); padding: 10px 20px; border-radius: 8px;">r (reconstructie)</span>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>14.1 Autoencodere Undercomplete</h4>
                <p>Copierea inputului la output pare inutila, dar scopul real este ca <strong>h</strong> sa captureze proprietati utile. O metoda este sa constrangem h sa aiba <strong>dimensiune mai mica decat x</strong> - aceasta se numeste autoencoder <strong>undercomplete</strong>. Forteaza modelul sa captureze cele mai importante caracteristici ale datelor de antrenament. Procesul de invatare minimizeaza functia de cost: <strong>L(x, g(f(x)))</strong>, de exemplu eroarea medie patratica.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Simulare: Undercomplete AE</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import torch
import torch.nn as nn

# Autoencoder undercomplete pentru MNIST
class UndercompleteAE(nn.Module):
    def __init__(self):
        super().__init__()
        # 784 -> 256 -> 64 -> 32 (bottleneck)
        self.encoder = nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 32)  # Cod: doar 32 dimensiuni!
        )
        # 32 -> 64 -> 256 -> 784
        self.decoder = nn.Sequential(
            nn.Linear(32, 64),
            nn.ReLU(),
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 784),
            nn.Sigmoid()
        )

    def forward(self, x):
        code = self.encoder(x)
        recon = self.decoder(code)
        return recon

# Loss: Mean Squared Error
loss_fn = nn.MSELoss()
# loss = L(x, g(f(x))) = ||x - recon||^2
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>Conexiunea cu PCA</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <h5>Autoencoder Liniar = PCA</h5>
                                <p>Cand encoderul si decoderul sunt <strong>liniare</strong> si functia de cost este <strong>MSE</strong>, autoencoderul undercomplete invata acelasi <strong>subspatiu principal</strong> ca PCA!</p>
                                <div style="background: var(--bg-dark); padding: 15px; border-radius: 8px; margin-top: 10px;">
                                    <p>Encoder liniar: h = Wx</p>
                                    <p>Decoder liniar: r = W'h</p>
                                    <p>Rezultat: W si W' span acelasi spatiu ca primele k componente principale</p>
                                </div>
                                <p style="margin-top: 10px; color: var(--text-secondary);">Autoencoderele neliniare insa pot invata o generalizare mult mai puternica a PCA!</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Vizualizare: Compresie vs Calitate</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="background: var(--bg-dark); padding: 20px; border-radius: 8px;">
                                <p style="text-align: center; margin-bottom: 15px;"><strong>Trade-off: Dimensiune Cod vs Reconstructie</strong></p>
                                <div style="display: flex; align-items: end; justify-content: space-around; height: 150px; padding: 0 20px;">
                                    <div style="text-align: center;">
                                        <div style="background: var(--success); width: 40px; height: 140px; border-radius: 4px 4px 0 0;"></div>
                                        <span style="font-size: 0.8rem;">784â†’32</span>
                                    </div>
                                    <div style="text-align: center;">
                                        <div style="background: var(--primary); width: 40px; height: 100px; border-radius: 4px 4px 0 0;"></div>
                                        <span style="font-size: 0.8rem;">784â†’16</span>
                                    </div>
                                    <div style="text-align: center;">
                                        <div style="background: var(--secondary); width: 40px; height: 60px; border-radius: 4px 4px 0 0;"></div>
                                        <span style="font-size: 0.8rem;">784â†’8</span>
                                    </div>
                                    <div style="text-align: center;">
                                        <div style="background: var(--warning); width: 40px; height: 30px; border-radius: 4px 4px 0 0;"></div>
                                        <span style="font-size: 0.8rem;">784â†’2</span>
                                    </div>
                                </div>
                                <p style="text-align: center; margin-top: 10px; font-size: 0.9rem; color: var(--text-secondary);">Inaltime = calitate reconstructie. Cod mai mic = mai multa compresie, dar pierdere de informatie.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Problema Capacitatii Excesive</h4>
                <p>Daca encoderul si decoderul au <strong>prea multa capacitate</strong>, autoencoderul poate invata sa copieze inputul fara a extrage informatii utile. Un encoder neliniar foarte puternic ar putea asocia fiecare exemplu x<sup>(i)</sup> cu un cod unic i, iar decoderul ar mapa inapoi i la x<sup>(i)</sup>. Aceasta nu este o problema in practica, dar ilustreaza de ce trebuie <strong>constrans</strong> autoencoderul.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Demonstratie: Memorare vs Generalizare</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
# Problema: Encoder prea puternic poate memora

import torch
import torch.nn as nn

class OverpoweredEncoder(nn.Module):
    """Encoder care poate memora perfect"""
    def __init__(self, n_samples):
        super().__init__()
        # Un lookup table - fiecare sample primeste cod unic
        self.lookup = nn.Embedding(n_samples, 1)
        self.sample_to_idx = {}  # Memoreaza maparea

    def forward(self, x, idx):
        # Returneaza cod unic per sample (nu invata nimic util!)
        return self.lookup(idx)

# Solutie: Constrangem capacitatea
# 1. Bottleneck (undercomplete)
# 2. Regularizare (sparse, denoising, contractive)
# 3. Noise injection
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
