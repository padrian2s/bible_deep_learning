<section class="page-section" id="page-513">
    <div class="page-header">
        <div class="page-number">513</div>
        <div class="page-title">
            <h3>Sparse Coding: Proprietati</h3>
            <span>Generalizare si Non-Parametric Encoder</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/page-513.jpg"
             alt="Pagina 513" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Avantajul Encoder-ului Non-Parametric</h4>
                <p>Encoder-ul bazat pe optimizare nu are <strong>eroare de generalizare</strong> - gaseste intotdeauna codul optim pentru orice input. Un encoder parametric (retea neurala) poate esua pe inputuri neasteptate.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Cand Conteaza?</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <p style="color: var(--text-secondary);">Coates & Ng (2011) au aratat ca sparse coding features generalizeaza mai bine pentru classification decat un autoencoder sigmoid.</p>
                            <p style="color: var(--text-secondary); margin-top: 10px;">Goodfellow et al. (2013d) au aratat ca sparse coding e mai bun cand avem <strong>foarte putine labels</strong> (20 sau mai putine per clasa).</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Dezavantajul Principal</h4>
                <p>Encoder-ul non-parametric necesita <strong>timp de calcul mare</strong> la test time (iteratii de optimizare). De asemenea, e greu de facut backpropagation prin el pentru fine-tuning supervizat.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Solutii Aproximative</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <p style="color: var(--text-secondary);">Bagnell & Bradley (2009) au propus versiuni diferentiabile care permit calculul aproximativ al derivatelor. Dar practic, sparse autoencoders (Cap. 14) sunt mai populari.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Spike and Slab Sparse Coding</h4>
                <p>O varianta: <strong>spike and slab</strong> model - foloseste un prior care pune multa masa exact la h<sub>i</sub>=0 (spike), nu doar aproape de zero. Genereaza samples cu valori exact zero.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>Problema cu Prior Continuu</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <p style="color: var(--text-secondary);">Cu prior Laplace, probabilitatea ca h<sub>i</sub>=0 exact e zero! Modelul genereaza samples cu multe valori mici, nu zero. Spike-and-slab rezolva asta.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>
