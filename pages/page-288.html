<section class="page-section" id="page-288">
    <div class="page-header">
        <div class="page-number">288</div>
        <div class="page-title">
            <h3>Capitolul 7 - Concluzie</h3>
            <span>Rezumat Regularizare pentru Deep Learning</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-288.jpg"
             alt="Pagina 288" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Rezumatul Capitolului 7</h4>
                <p>Acest capitol a descris cele mai importante strategii de regularizare pentru retele neurale. Regularizarea este o tema centrala in machine learning si va fi revizitata periodic in capitolele urmatoare. Alta tema centrala este <strong>optimizarea</strong>, descrisa in capitolul urmator.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">âœ¨</div>
                        <span>Tehnici Acoperite</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div style="display: grid; grid-template-columns: repeat(2, 1fr); gap: 10px;">
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.1</strong> Parameter Norm Penalties (LÂ², LÂ¹)
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.2</strong> Norm Penalties as Constraints
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.3</strong> Under-Constrained Problems
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.4</strong> Dataset Augmentation
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.5</strong> Noise Robustness
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.6</strong> Semi-Supervised Learning
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.7</strong> Multi-Task Learning
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.8</strong> Early Stopping
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.9</strong> Parameter Tying/Sharing
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.10</strong> Sparse Representations
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.11</strong> Bagging & Ensembles
                                </div>
                                <div style="padding: 10px; background: var(--primary); color: white; border-radius: 8px;">
                                    <strong>7.12</strong> Dropout (cel mai important!)
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.13</strong> Adversarial Training
                                </div>
                                <div style="padding: 10px; background: var(--bg-lighter); border-radius: 8px;">
                                    <strong>7.14</strong> Tangent Methods
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>Mesajul Principal</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <p>Cel mai bun model (cu cea mai mica eroare de generalizare) este aproape intotdeauna un <strong>model mare care a fost regularizat corespunzator</strong>, nu un model mic fara regularizare.</p>
                            </div>
                            <p style="margin-top: 15px;">Regularizarea permite: expresivitate inalta + generalizare buna. Costul: mai mult compute, mai multi hiperparametri de tunat. Dar rezultatele merita!</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Ce urmeaza: Capitolul 8 - Optimizare</h4>
                <p>Capitolul urmator acopera o alta tema centrala: <strong>optimizarea</strong> pentru deep learning. Vom vedea SGD, momentum, Adam, si multe alte tehnici pentru antrenarea eficienta a retelelor neurale.</p>
            </div>
        </div>

    </div>
</section>
