<section class="page-section" id="page-156">
    <div class="page-header">
        <div class="page-number">156</div>
        <div class="page-title">
            <h3>Support Vector Machines</h3>
            <span>Capitolul 5 - Sectiunea 5.7.2</span>
        </div>
    </div>
    <div class="image-container">
        <img src="book_page_jpg/page-156.jpg"
             alt="Pagina 156" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>5.7.2 Support Vector Machines</h4>
                <p>Una dintre cele mai influente abordari ale supervised learning este <strong>support vector machine</strong> (SVM) (Boser et al. 1992; Cortes and Vapnik 1995). Modelul este similar cu logistic regression - e condus de o functie liniara w<sup>T</sup>x + b. Spre deosebire de logistic regression, SVM nu produce probabilitati ci doar identitatea clasei: prezice clasa pozitiva cand w<sup>T</sup>x + b > 0, clasa negativa cand w<sup>T</sup>x + b < 0.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">ðŸ“š</div>
                        <span>Referinte SVM</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="reference-list">
                                <div class="reference-item">
                                    <strong>Boser et al. (1992)</strong> - A training algorithm for optimal margin classifiers
                                </div>
                                <div class="reference-item">
                                    <strong>Cortes and Vapnik (1995)</strong> - Support-vector networks
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Kernel Trick</h4>
                <p>O inovatie cheie asociata cu SVM este <strong>kernel trick</strong>. Consta din observatia ca multe algoritmi ML pot fi scrise exclusiv in termeni de <strong>dot products</strong> intre exemple. De exemplu, functia liniara SVM poate fi rescrisa ca:</p>
                <div class="formula" style="text-align: center; font-size: 1.2rem; margin: 15px 0; padding: 15px; background: var(--bg-dark); border-radius: 8px;">
                    w<sup>T</sup>x + b = b + Î£áµ¢ Î±áµ¢ x<sup>T</sup>x<sup>(i)</sup>
                </div>
                <p>Inlocuim x cu output-ul unei feature function Ï†(x) si dot product-ul cu o functie <strong>kernel</strong> k(x, x<sup>(i)</sup>) = Ï†(x)<sup>T</sup>Ï†(x<sup>(i)</sup>). Aceasta ne permite sa invatam modele nonliniare!</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">ðŸŽ®</div>
                        <span>Simulare: SVM cu Kernel</span>
                        <span class="arrow">â–¶</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
from sklearn.svm import SVC
import numpy as np

# Date XOR (neseparabile liniar!)
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 0])

# SVM liniar - NU poate rezolva XOR
svm_linear = SVC(kernel='linear')
svm_linear.fit(X, y)
print("SVM Linear accuracy:", svm_linear.score(X, y))

# SVM cu kernel RBF - POATE rezolva XOR!
svm_rbf = SVC(kernel='rbf')
svm_rbf.fit(X, y)
print("SVM RBF accuracy:   ", svm_rbf.score(X, y))

print()
print("=> Kernel trick permite clasificare nonliniara")
print("   cu algoritm liniar in spatiul transformat!")
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
