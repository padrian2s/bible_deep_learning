<section class="page-section" id="page-115">
    <div class="page-header">
        <div class="page-number">115</div>
        <div class="page-title">
            <h3>Clasificare</h3>
            <span>Capitolul 5 - Tipuri de Task-uri ML</span>
        </div>
    </div>
    <div class="image-container">
        <img src="../book_page_jpg/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT)-page-115.jpg"
             alt="Pagina 115" class="page-image" onclick="zoomImage(this)">
    </div>
    <div class="explanation-content">
        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Clasificare (Classification)</h4>
                <p>In acest tip de task, programul trebuie sa specifice carei din k categorii apartine input-ul. Pentru a rezolva acest task, algoritmul invata o functie <strong>f: ‚Ñù‚Åø ‚Üí {1, ..., k}</strong>. Cand y = f(x), modelul asigneaza vectorul x categoriei identificate de codul numeric y. Exista variante in care f produce o distributie de probabilitate peste clase. Un exemplu de clasificare este <strong>recunoasterea obiectelor</strong>, unde input-ul este o imagine si output-ul este un cod numeric pentru obiectul din imagine.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Clasificare cu Probabilitati</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression

# Incarcare dataset Iris (3 clase de flori)
iris = load_iris()
X, y = iris.data, iris.target

# Antrenare clasificator
clf = LogisticRegression(max_iter=200)
clf.fit(X, y)

# Predictie pentru un exemplu nou
x_new = [[5.1, 3.5, 1.4, 0.2]]

# Clasificare hard: o singura clasa
prediction = clf.predict(x_new)
print(f"Clasa prezisa: {iris.target_names[prediction[0]]}")

# Clasificare soft: probabilitati
probs = clf.predict_proba(x_new)[0]
print("\nProbabilitati per clasa:")
for name, prob in zip(iris.target_names, probs):
    bar = "‚ñà" * int(prob * 20)
    print(f"  {name:12s}: {prob:.3f} {bar}")
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon reference">üìö</div>
                        <span>Aplicatii Deep Learning</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="reference-list">
                                <div class="reference-item">
                                    <strong>ImageNet (Krizhevsky et al., 2012)</strong> - AlexNet a revolutionat recunoasterea imaginilor cu CNN-uri
                                </div>
                                <div class="reference-item">
                                    <strong>Recunoastere faciala (Taigman et al., 2014)</strong> - DeepFace permite tagging automat in fotografii
                                </div>
                                <div class="reference-item">
                                    <strong>Willow Garage PR2</strong> - Robot care recunoaste si livreaza bauturi la comanda
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="interactive-paragraph">
            <div class="paragraph-main" onclick="toggleParagraph(this)">
                <h4>Clasificare cu Input-uri Lipsa</h4>
                <p>Clasificarea devine mai complexa cand nu toate masuratorile din vectorul de input sunt garantate disponibile. Pentru a rezolva aceasta problema, in loc sa invatam o singura functie de clasificare, algoritmul trebuie sa invete un <strong>set de functii</strong> - cate una pentru fiecare subset posibil de input-uri lipsa. Aceasta situatie apare frecvent in <strong>diagnosticul medical</strong>, unde multe teste sunt costisitoare sau invazive.</p>
            </div>
            <div class="expandable-sections">
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon simulation">üéÆ</div>
                        <span>Simulare: Handling Missing Data</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="code-block">
import numpy as np

# Problema: Diagnostic cu date lipsa
# Features: [temperatura, tensiune, analiza_sange]
# Cu n features, avem 2^n combinatii posibile de date lipsa!

n_features = 3
n_combinations = 2 ** n_features
print(f"Cu {n_features} features, avem {n_combinations} scenarii posibile")

# Solutie eficienta: Model probabilistic joint
# Invatam P(y, x1, x2, x3) si marginalizam pe features lipsa

# Exemplu simplificat
def predict_with_missing(model_joint, x_observed, mask):
    """
    model_joint: distributia comuna P(y, x1, ..., xn)
    x_observed: valorile observate
    mask: boolean array, True = observat
    """
    # Marginalizam pe variabilele lipsa
    # P(y | x_observed) = sum over x_missing of P(y, x_all)
    pass

print("\nAvantaj: Un singur model inlocuieste 2^n modele!")
print("Deep probabilistic models (VAE, etc.) pot face asta eficient")
                            </div>
                        </div>
                    </div>
                </div>
                <div class="section-tab">
                    <div class="section-header" onclick="toggleSection(this)">
                        <div class="section-icon animation">‚ú®</div>
                        <span>Vizualizare: Distributie Probabilistica</span>
                        <span class="arrow">‚ñ∂</span>
                    </div>
                    <div class="section-content">
                        <div class="section-body">
                            <div class="key-concept">
                                <h5>Solutia Eleganta</h5>
                                <p>In loc de 2‚Åø clasificatoare separate, invatam o singura <strong>distributie de probabilitate comuna</strong> peste toate variabilele relevante:</p>
                                <div class="formula" style="text-align: center; margin: 15px 0;">
                                    <p style="font-size: 1.2rem;">P(y, x‚ÇÅ, x‚ÇÇ, ..., x‚Çô)</p>
                                </div>
                                <p>Pentru a clasifica cu features lipsa, <strong>marginalizam</strong> pe variabilele neobservate:</p>
                                <div class="formula" style="text-align: center; margin: 15px 0;">
                                    <p style="font-size: 1.1rem;">P(y | x<sub>obs</sub>) = Œ£<sub>x<sub>missing</sub></sub> P(y, x<sub>all</sub>)</p>
                                </div>
                            </div>
                            <div class="reference-item" style="margin-top: 15px;">
                                <strong>Goodfellow et al. (2013b)</strong> - Modele probabilistice deep pentru clasificare cu input-uri lipsa
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>
